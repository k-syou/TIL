### Transformer

Transformer는 병렬처리를 통해 순차처리의 한계를 극복한 모델입니다. 문맥 속에서 단어들 사이의 연관관계를 파악하여 더 정확한 결과를 도출합니다. 이 연관관계는 단어들 간의 가까운 정도(확률)로 표현됩니다.

Transformer는 인코더와 디코더로 구성됩니다:
- **인코더**: 대량의 데이터를 압축하는 과정으로, 대량의 데이터를 어텐션 매커니즘을 통해 모델에 입력합니다.
- **디코더**: 일부분의 데이터(프롬프트)를 모델에 입력하여 응답을 생성합니다.

예를 들어, '왕'은 '남자'와, '왕비'는 '여자'와 연관이 있으며, 셰익스피어나 플라톤 같은 작가는 햄릿이나 로미오와 같은 작품과 연관이 있습니다.